# LLM Provider Configuration
# Available providers: ollama, openai
DEFAULT_PROVIDER=ollama

# Ollama Configuration
OLLAMA_MODEL=qwen2.5-coder:14b
OLLAMA_MODEL_FILE_SYSTEM=qwen2.5-coder:7b
OLLAMA_BASE_URL=http://localhost:11434/v1

# OpenAI Configuration
OPENAI_MODEL=gpt-4o
OPENAI_API_KEY=your-api-key-here

# Agent-specific Provider Overrides
CODE_CONVERTER_PROVIDER=ollama
EXPLANATION_PROVIDER=ollama
TERMINAL_PROVIDER=ollama
FILE_SYSTEM_PROVIDER=ollama
AWS_CLI_PROVIDER=ollama
DEV_ENV_PROVIDER=ollama
TERRAFORM_PROVIDER=ollama
DUCK_BROWSER_PROVIDER=ollama 